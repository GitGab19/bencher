import { BENCHER_VERSION } from "../../../site/util";

## What is Bencher?

Bencher is a suite of open source tools designed to catch performance regressions in CI. If you believe [performance is a feature](https://blog.codinghorror.com/performance-is-a-feature), then Bencher is the tool you have been missing.

Though Bencher is open source, there is also a hosted SaaS version available at [bencher.dev](https://bencher.dev).

## Clone the Repo

In order to work through this tutorial you will need to have `git` installed. Check to see if you have `git` installed.

Run: `git --version`

You should see something like:

```
$ git --version
git version 2.37.3
```

It is okay if your version number is different. It's just important that this command works. If not follow the [instructions for installing `git`](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).

<br />

With `git` installed, we can now clone the Bencher repository.

Run: `git clone https://github.com/bencherdev/bencher.git`

You should see something like:

```
$ git clone https://github.com/bencherdev/bencher.git
Cloning into 'bencher'...
remote: Enumerating objects: 24752, done.
remote: Counting objects: 100% (7363/7363), done.
remote: Compressing objects: 100% (2396/2396), done.
remote: Total 24752 (delta 4862), reused 7274 (delta 4785), pack-reused 17389
Receiving objects: 100% (24752/24752), 4.92 MiB | 12.43 MiB/s, done.
Resolving deltas: 100% (16108/16108), done.
```

Again, it is okay if your output is different. It's just important that this command works.

Finally, navigate into the Bencher repo that you just cloned.

Run: `cd bencher`

## Install `bencher` CLI

In order to install the `bencher` CLI you will need to have `cargo` installed. Check to see if you have `cargo` installed.

Run: `cargo --version`

You should see something like:

```
$ cargo --version
cargo 1.65.0 (4bc8f24d3 2022-10-20)
```

It is okay if your version number is different. It's just important that this command works. If not follow the [instructions for installing `cargo` via `rustup`](https://rustup.rs/).

<br />

With `cargo` installed, we can install the `bencher` CLI.

Run: `cargo install --path services/cli --locked`

You should see something like:

<pre>
  <code>
    {`$ cargo install --path services/cli --locked
  Installing bencher_cli v${BENCHER_VERSION} (/workspace/bencher/services/cli)
    Updating crates.io index
    ...
    Finished release [optimized] target(s) in 0.27s
  Installing /workspace/.cargo/bin/bencher
   Installed package \`bencher_cli v${BENCHER_VERSION} (/workspace/bencher/services/cli)\` (executable \`bencher\`)`}
  </code>
</pre>

Again, it is okay if your output is different. It's just important that this command works.

> üê∞ Note: When running this command, you should be in the root folder of the Bencher repo.

<br />

Finally, lets test that we have the `bencher` CLI installed.

Run: `bencher --version`

You should see something like:

<pre>
  <code>
    {`$ bencher --version
bencher ${BENCHER_VERSION}`}
  </code>
</pre>

As before, it is okay if your version number is different. It's just important that this command works.

## Run UI & API Servers

In order to run the UI and API servers in this tutorial you will need to have `docker` installed. Check to see if you have `docker` installed.

Run: `docker --version`

You should see something like:

```
$ docker --version
Docker version 20.10.17, build 100c701
```

It is okay if your version number is different. It's just important that this command works. If not follow the [instructions for installing `docker`](https://docs.docker.com/get-docker/).

<br />

With `docker` installed, we can now run the UI and API servers.

Run: `docker compose up -d`

You should see something like:

```
$ docker compose up -d
[+] Running 16/16
 ‚†ø bencher_ui Pulled                                           5.9s
 ...
 ‚†ø bencher_api Pulled                                          6.3s
 ...
[+] Running 3/3
 ‚†ø Network bencher_default      Started                        0.1s
 ‚†ø Container bencher_ui         Started                        0.8s
 ‚†ø Container bencher_api_local  Started                        0.4s
```

Again, it is okay if your output is different. It's just important that this command works.

<br />

Next, check to see both docker containers are running.

Run: `docker ps`

You should see something like:

```
$ docker ps
CONTAINER ID   IMAGE                                 COMMAND                  CREATED              STATUS              PORTS                                           NAMES
1d2ed7c7481e   bencherdev/bencher-ui:latest          "/docker-entrypoint.‚Ä¶"   About a minute ago   Up About a minute   0.0.0.0:3000->80/tcp, :::3000->80/tcp           bencher_ui
7a8590d7021a   bencherdev/bencher-api-local:latest   "/api"                   About a minute ago   Up About a minute   0.0.0.0:61016->61016/tcp, :::61016->61016/tcp   bencher_api_local
```

As before, it is okay if your output is different. It's just important that this command works.

<br />

With the `bencher` CLI installed and the services running, we should now be able to run a command from the `bencher` CLI that talks to our Bencher API server.

Run: `bencher server version --host http://localhost:61016`

You should see something like:

<pre>
  <code>
    {`$ bencher server version --host http://localhost:61016
{
  "version": "${BENCHER_VERSION}"
}`}
  </code>
</pre>

It is okay if the version number is different. It's just important that this command works.

## Create an Account

In order to user the Bencher API server beyond a few basic commands, like checking the version number, you will need to create an account on your API server.

<br />

First, lets set our hostname as an environment variable, so we don't have to provide it with the `--host` flag on every single command.

Run: `export BENCHER_HOST=http://localhost:61016`

If you then run: `echo $BENCHER_HOST`

You should see:

```
$ echo $BENCHER_HOST
http://localhost:61016
```

<br />

> üê∞ Note: The `bencher` CLI defaults to [https://api.bencher.dev](https://api.bencher.dev) as the host, so when using the hosted SaaS version of Bencher this step is not required.

<br />

Now lets create an account.

Run: `bencher auth signup --name "Saul Goodman" saul@bettercallsaul.com`

You should see:

```
$ bencher auth signup --name "Saul Goodman" saul@bettercallsaul.com
{}
```

Because we haven't set up email on the API server yet, the invite code that we need is going to be in the server logs.

Run: `docker compose logs bencher_api`

You should see something like:

```
bencher_api_local  | 2022-12-19T16:45:19.353613Z  INFO bencher_api::context::messenger:
bencher_api_local  | To: Saul Goodman <saul@bettercallsaul.com>>
bencher_api_local  | Subject: Confirm Bencher Signup
bencher_api_local  | Body:
bencher_api_local  | Ahoy Saul Goodman,
bencher_api_local  | Please, click the button below or use the provided code to signup for Bencher.
bencher_api_local  | Confirm Email: http://localhost:3000/auth/confirm?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJhdXRoIiwiZXhwIjoxNjcxNDcwMTE5LCJpYXQiOjE2NzE0NjgzMTksImlzcyI6ImJlbmNoZXIuZGV2Iiwic3ViIjoic2F1bEBiZXR0ZXJjYWxsc2F1bC5jb20iLCJvcmciOm51bGx9.WrLWRINLwa9Nzo6GDzKtNE8b9y732PBMFxlimvru63s
bencher_api_local  | Confirmation Code: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJhdXRoIiwiZXhwIjoxNjcxNDcwMTE5LCJpYXQiOjE2NzE0NjgzMTksImlzcyI6ImJlbmNoZXIuZGV2Iiwic3ViIjoic2F1bEBiZXR0ZXJjYWxsc2F1bC5jb20iLCJvcmciOm51bGx9.WrLWRINLwa9Nzo6GDzKtNE8b9y732PBMFxlimvru63s
bencher_api_local  |
bencher_api_local  | See you soon,
bencher_api_local  | The Bencher Team
bencher_api_local  | Bencher - Continuous Benchmarking
bencher_api_local  | Manage email settings (http://localhost:3000/console/settings/email)
```

Your output should be sligtly different than the above, namely the Confirmation Code. It's just important that this command works. Take note of the Confirmation Code.

<br />

Next, we will use the Confirmation Code from the API server logs to confirm your signup. Substitute your Confirmation Code for `YOUR_CONFIRMATION_CODE` in the following command.

Run: `bencher auth confirm YOUR_CONFIRMATION_CODE`

You should see something like:

```
$ bencher auth confirm YOUR_CONFIRMATION_CODE
{
  "token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJjbGllbnQiLCJleHAiOjE2NzQwNjA3NTAsImlhdCI6MTY3MTQ2ODc1MCwiaXNzIjoiYmVuY2hlci5kZXYiLCJzdWIiOiJzYXVsQGJldHRlcmNhbGxzYXVsLmNvbSIsIm9yZyI6bnVsbH0.CABcvWlPobAHs7wsdR6wX5p0R2jaCd7RmpsnMp5pwEc",
  "user": {
    "admin": true,
    "email": "saul@bettercallsaul.com",
    "locked": false,
    "name": "Saul Goodman",
    "slug": "saul-goodman",
    "uuid": "e8938f3a-d8cb-4ba5-b09e-5b5a29169c51"
  }
}
```

Again, your output should be sligtly different than the above. It's just important that this command works. Take note of the `token` field.

<br />

Finally, lets set our session token as an environment variable, so we don't have to provide it with the `--token` flag on every single command. Substitute your `token` field for `YOUR_TOKEN` in the following command.

Run: `export BENCHER_API_TOKEN=YOUR_TOKEN`

If you then run: `echo $BENCHER_API_TOKEN`

You should see:

```
$ echo $BENCHER_API_TOKEN
YOUR_TOKEN
```

<br />

> üê∞ Note: This this is only a session token, and it will expire within a few weeks. Longer lived API tokens are available, but they will not be covered in this tutorial.

## Create a Project

Now that we have a user account and API token, we can create a project. First, we need to know which organization our new project will belong to.

Run: `bencher org ls`

You should see something like:

```
$ bencher org ls
[
  {
    "name": "Saul Goodman",
    "slug": "saul-goodman",
    "uuid": "4581feb0-6cac-40a9-bd8a-d7865183b01e"
  }
]
```

Your output should be sligtly different than the above, as the `uuid` is pseudorandom. It's just important that this command works. Take note of the `slug` field, `saul-goodman`.

<br />

We can now create a new project inside of this organization.

Run: `bencher project create --org saul-goodman --url http://www.savewalterwhite.com "Save Walter White"`

You should see something like:

```
$ bencher project create --org saul-goodman --url http://www.savewalterwhite.com "Save Walter White"
{
  "name": "Save Walter White",
  "organization": "4581feb0-6cac-40a9-bd8a-d7865183b01e",
  "public": true,
  "slug": "save-walter-white",
  "url": "http://www.savewalterwhite.com",
  "uuid": "c6c2a8e8-685e-4413-9a19-5b79053a71b1"
}
```

Again, your output should be sligtly different than the above, as the `uuid` is pseudorandom. It's just important that this command works. Take note of the `slug` field, `save-walter-white`.

## Run a Report

We are finally ready to collect some benchmark metrics! For simplicity's sake, we will be using mock data in this tutorial.

Run: `bencher mock`

You should see something like:

```
$ bencher mock
{
  "bencher::mock_0": {
    "latency": {
      "value": 506.876116608852,
      "lower_bound": 479.6595339197462,
      "upper_bound": 534.0926992979578
    }
  },
  "bencher::mock_1": {
    "latency": {
      "value": 207.5098520049996,
      "lower_bound": 202.9429996814694,
      "upper_bound": 212.07670432852981
    }
  },
  "bencher::mock_2": {
    "latency": {
      "value": 2204.9953162182187,
      "lower_bound": 2080.9181820897516,
      "upper_bound": 2329.072450346686
    }
  }
  "bencher::mock_3": {
    "latency": {
      "value": 1101.3243640332075,
      "lower_bound": 1091.7884305874131,
      "upper_bound": 1110.860297479002
    }
  },
  "bencher::mock_4": {
    "latency": {
      "value": 182.36903617911693,
      "lower_bound": 172.65530563428618,
      "upper_bound": 192.08276672394769
    }
  }
}
```

Your output should be sligtly different than the above, as the data are pseudorandom. It's just important that this command works.

<br />

Now lets run a report using mock benchmark metric data.

Run: `bencher run --project save-walter-white "bencher mock"`

You should see something like:

```
$ bencher run --project save-walter-white "bencher mock"
{
  "bencher::mock_0": {
    "latency": {
      "value": 550.9386870323959,
      "lower_bound": 523.4050559446542,
      "upper_bound": 578.4723181201376
    }
  },
  "bencher::mock_1": {
    "latency": {
      "value": 659.2390251410347,
      "lower_bound": 657.5172723361218,
      "upper_bound": 660.9607779459477
    }
  },
  "bencher::mock_2": {
    "latency": {
      "value": 1837.850537908266,
      "lower_bound": 1679.3581823266893,
      "upper_bound": 1996.3428934898427
    }
  },
  "bencher::mock_3": {
    "latency": {
      "value": 1356.976684331241,
      "lower_bound": 1314.4915123223968,
      "upper_bound": 1399.461856340085
    }
  },
  "bencher::mock_4": {
    "latency": {
      "value": 3849.2087495791616,
      "lower_bound": 3646.5361513563394,
      "upper_bound": 4051.881347801984
    }
  }
}

{
  "branch": "main",
  "hash": null,
  "testbed": "localhost",
  "start_time": "2023-01-18T13:52:57.678003725Z",
  "end_time": "2023-01-18T13:52:57.682390145Z",
  "results": [
    "{\n  \"bencher::mock_0\": {\n    \"latency\": {\n      \"value\": 550.9386870323959,\n      \"lower_bound\": 523.4050559446542,\n      \"upper_bound\": 578.4723181201376\n    }\n  },\n  \"bencher::mock_1\": {\n    \"latency\": {\n      \"value\": 659.2390251410347,\n      \"lower_bound\": 657.5172723361218,\n      \"upper_bound\": 660.9607779459477\n    }\n  },\n  \"bencher::mock_2\": {\n    \"latency\": {\n      \"value\": 1837.850537908266,\n      \"lower_bound\": 1679.3581823266893,\n      \"upper_bound\": 1996.3428934898427\n    }\n  },\n  \"bencher::mock_3\": {\n    \"latency\": {\n      \"value\": 1356.976684331241,\n      \"lower_bound\": 1314.4915123223968,\n      \"upper_bound\": 1399.461856340085\n    }\n  },\n  \"bencher::mock_4\": {\n    \"latency\": {\n      \"value\": 3849.2087495791616,\n      \"lower_bound\": 3646.5361513563394,\n      \"upper_bound\": 4051.881347801984\n    }\n  }\n}\n"
  ],
  "settings": {
    "adapter": null,
    "fold": null,
    "allow_failure": false
  }
}
{
  "adapter": "magic",
  "alerts": [],
  "end_time": "2022-12-20T16:01:21.526691505Z",
  "results": [
    "babf3c2c-30c2-4e2a-ada4-17c7ad0fafff",
    "3d86b33a-4505-4762-8132-830cfd0dc6d6",
    "b5aef1a4-ec01-41c2-9adf-f9eb26f97893",
    "d9a6e82a-2dc6-4e40-a059-6282a62e30c0",
    "2aca6972-835a-4f97-bb0d-d452ef73eac9"
  ],
  "start_time": "2022-12-20T16:01:21.523728845Z",
  "testbed": "abb0fbe0-0550-4f80-b53f-37d89303e6b8",
  "user": "14a828c8-7eb4-4f78-ad0f-ea7a2b9b06e6",
  "uuid": "524b5016-87af-4484-8817-247b0e0d01c7",
  "version": "70a228ed-eb20-42a3-89b9-3ebebc5c2593"
}
```

Again, your output should be sligtly different than the above, as the data are pseudorandom. It's just important that this command works.

<br />

Now, lets rerun this same command again to generate more data.

Rerun: `bencher run --project save-walter-white "bencher mock"`

<br />

You can now view your results on your project's perf page at [localhost:3000/perf/save-walter-white](http://localhost:3000/perf/save-walter-white).

Select:

- `Latency` from the `Metric Kind` dropdown
- `main` from the `Branches` tab
- `localhost` from the `Testbeds` tab
- `bencher::mock_0` and `bencher::mock_1` from the `Benchmarks` tab

<br />

> üê∞ Note: The project's perf page URL is based off of the project `slug`, that is why it is `save-walter-white`.

<br />

üéâ Congrats! You tracked your first benchmarks!
