Thresholds can be created for the unique combination of a Metric Kind, Branch, and Testbed.
They are statistical significance tests that use either a
[Z-score](https://en.wikipedia.org/wiki/Standard_score)
or [Student's t-test](https://en.wikipedia.org/wiki/Student%27s_t-test)
in order to detect performance regressions and gerenerate Alerts.
When a Metric is below a Threshold's left side boundary or above a Threshold's right side boundary,
an Alert is generated for that Metric.

Thresholds work best when:
- There are no extreme differences between benchmark runs
- Benchmark runs are totally independent of one another
- The number of iterations for a single benchmark run is less than 10% of the historical Metrics
- There are at least 30 historical Metrics for the combination of Metric Kind, Branch, and Testbed

If there are less than 30 historical Metrics for the combination of Metric Kind, Branch, and Testbed
then a Student's t-test Threshold should be used and __*not*__ a Z-score Threshold.

<div class="content has-text-centered">
    <figure>
<img
    src="https://upload.wikimedia.org/wikipedia/commons/2/25/The_Normal_Distribution.svg"
    width="800"
    height="600"
    alt="The Normal Distribution https://commons.wikimedia.org/wiki/File:The_Normal_Distribution.svg"
/>
<br/>
<small>üê∞ Don't Panic! This will all make sense in a minute.</small>
</figure>
</div>

## Statistical Significance Test

### Z-score

The Z-score measures the number of [standard deviations](https://en.wikipedia.org/wiki/Standard_deviation) (œÉ) a given Metric is above or below the mean of the historical Metrics.
The standard deviation (œÉ) can also be expressed as a _left_ side or _right_ side cumulative percentage.

For example, two standard deviations (2œÉ) is the same as a _right_ side cumulative percentage of 97.7%, as pictured above.
When creating Z-score Thresholds, the decimal notation of the cumulative percentage is used.
In this example, the _right_ side cumulative percentage of 97.7% would be a Right Side Boundary of `0.977`.
In practice, a Threshold like this would be useful for the Latency Metric Kind.
That is, a larger value would indicate a performance regression.

When a smaller value would indicate a performance regression such as with the Throughput Metric Kind,
a _left_ side cumulative percentage should be used.
A _left_ side cumulative percentage of 97.7% would correspond to two standard deviations below the mean (-2œÉ).
This would be given in decimal notation as a Left Side Boundary of `0.977`.

### Student's t-test

The Student's t-test measures how likely it is that a given Metric is above or below the mean of the historical Metrics.
This likelihood is called a confidence interval (CI).
The confidence interval (CI) is expressed as a _left_ side or _right_ side confidence percentage.

For example, a _right_ side confidence percentage of 95.0% indicates that 95.0% of Metrics should be _less_ than an expected _maximum_.
When creating t-test Thresholds, the decimal notation of the confidence percentage is used.
In this example, the _right_ side confidence percentage of 95.0% would be a Right Side Boundary of `0.95`.
In practice, a Threshold like this would be useful for the Latency Metric Kind.
That is, a larger value would indicate a performance regression.

When a smaller value would indicate a performance regression such as with the Throughput Metric Kind,
a _left_ side confidence percentage should be used.
A _left_ side confidence percentage of 95.0% would indicate that Metrics should be _greater_ than an expected _minimum_.
This would be given in decimal notation as a Left Side Boundary of `0.95`.

## Statistical Significance Boundary

The meaning of the statistical significance boundary depends on the statistical significance test:
- Z-score: Standard deviation (œÉ) expressed as a decimal cumulative percentage
- t-test: Confidence interval (CI) expressed as a decimal confidence percentage

> üê∞ Tip: To fail a CI build when a boundary is violated use the `--err` flag for the `bencher run` CLI command.

### Left Side Boundary
A left side boundary can be set for a Threshold.
It is used when a smaller value would indicate a performance regression,
such as with the Throughput Metric Kind.
The value must be a decimal between `0.5` and `1.0`.

### Right Side Boundary
A right side boundary can be set for a Threshold.
It is used when a larger value would indicate a performance regression,
such as with the Latency Metric Kind.
The value must be a decimal between `0.5` and `1.0`.

## Sample Size

### Minimum Sample Size
A minimum sample size can be set for a Threshold.
The Threshold will only run its statistical significance test
if the number of historical Metrics is greater than or equal to the minimum sample size.

### Maximum Sample Size
A maximum sample size can be set for a Threshold.
The Threshold will limit itself to only the most recent historical Metrics
capped at the maximum sample size for its statistical significance test.

## Window Size
A window size in seconds can be set for a Threshold.
The Threshold will limit itself to only the most recent historical Metrics
bounded by the given time window for its statistical significance test.

## Alerts
Alerts are generated when a Metric is below a Threshold's left side boundary or above a Threshold's right side boundary. To fail a CI build in the event of an Alert set the `--err` flag when using the `bencher run` CLI command.

### Suppressing Alerts
Sometimes it can be useful to supress Alerts for a particular Benchmark.
The best way to do this is by adding one of these special suffixes to that Benchmark's name:

- `_bencher_ignore`
- `BencherIgnore`
- `-bencher-ignore`

For example, if your Benchmark was named `my_flaky_benchmark` then renaming it to `my_flaky_benchmark_bencher_ignore`
would ignore just that particular Benchmark going forward.
Ignored Benchmarks do not get checked against the Threshold even if one exists.
Be careful when changing the name of your Benchmarks though.
There is currently no way for Bencher to track this change,
so the renamed Benchmark will be considered a brand new Benchmark.
If you remove the suffix and return to the original Benchmark name,
then things will pick right back up where you left off though.

<br />
<br />

> üê∞ Congrats! You have learned all about Thresholds & Alerts! üéâ

<br/>

<h2><a href="/docs/how-to/track-benchmarks">Keep Going: How to use Bencher to Track Benchmarks ‚û°</a></h2>